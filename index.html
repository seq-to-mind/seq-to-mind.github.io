<!DOCTYPE html>
<html>

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    <meta name="title" content="Zhengyuan Liu | Institute for Infocomm Research, A*STAR">
    <meta name="description" content="Zhengyuan Liu is currently the Asst. Head of the AI4EDU Programme, and the Tech Lead of Multimodal Generative AI @I2R, A*STAR, Singapore.">
    <meta name="keywords" content="zhengyuan liu, generative AI, human-centered AI, large language models">
    <meta name="author" content="Zhengyuan Liu">
    <meta name="google-site-verification" content="gEQQW3Rysd1uOa2M3W9man_Ub5ExM2PCxCyg6ZfSJLw" />
    <link href="css/bootstrap.css" rel="stylesheet" media="screen">
    <link href="css/my-style.css" rel="stylesheet" media="screen">
    <script src="js/jquery.js"></script>
    <script src="js/bootstrap.js"></script>
    <title>Zhengyuan Liu | Institute for Infocomm Research, A*STAR</title>
</head>

<body>
<header></header>

<div class="container">
    <div>
        <h1>
            Zhengyuan Liu
        </h1>
        <div class="row">
            <div class="col-sm-7">
                <p>
                    Asst. Head of the AI4EDU Programme<br>
                    Tech Lead of Multimodal Generative AI Group<br>
                    Institute for Infocomm Research<br>
                    Agency for Science, Technology and Research (A*STAR), Singapore<br>
                    IEEE Senior Member<br>
                </p>
                <p>
                    [<a href="mailto:i.liuzhengyuan@gmail.com">Email</a>]&nbsp;&nbsp;
                    [<a href="https://scholar.google.com.sg/citations?user=tqzidGsAAAAJ">Google Scholar</a>]&nbsp;&nbsp;
                    [<a href="https://www.linkedin.com/in/zhengyuanliu">LinkedIn</a>]&nbsp;&nbsp;
                </p>
                <p>
                    <span class="label label-danger">Research Interest</span><br>
                    Multimodal and Multilingual Foundation Models.<br>
                    Generative AI for Education, Healthcare, and Life Science.<br>
                    Accessibility, Reliability, and Explainability for Human-Centered AI.<br>
                </p>
            </div>
            <div class="col-sm-5" align="middle">
                <img src="assets/img/Zhengyuan_Photo.jpg" class="img-responsive" alt="Zhengyuan"
                     width="148">
            </div>
        </div>
        <hr>
        <p>
            <font size="3">
                <b>Current Key Projects</b><br>
                ğŸŒŸ Human-centered AI | AI for Education Programme <br>
                > We conduct interdisciplinary research on how humans and intelligent systems (not limited to LLMs) can effectively and efficiently learn from each other, and explore the world and universe together.<br>
                > We are building the Special Interest Group on Human-AI Collaborative Learning, Exploration, and Discovery (<a href="https://sigcoled.github.io/">InspAIre</a>).<br><br>
                ğŸš€ National Large Language Model Programme (MERaLiON SG)<br>
                > Working on improving multilingual and multimodal LLMs' capabilities of knowledge and reasoning.<br>
                <p>
                    <i> â–º â€œImagination is more important than knowledge.â€ â€“ Albert Einstein.</i>
                <p>
            </font>
        </p>
        <hr>
        <p>
            <font size="3">
                <b>Join Us & Collaboration (ğŸ“§ just email me)</b><br>
                â—‹ Research Assistant / Student Intern in Human-centered AI. Remote intern is also welcome!<br>
                <span style="padding-left: 0px;"> <span class="label label-info">Topic</span> Conversational intelligent tutoring systems, Human-AI collaborative learning, etc.</span><br>
                â—‹ Research Assistant / Student Intern in Generative AI and Multimodal Fundation Models.<br>
                <span style="padding-left: 0px;"><span class="label label-info">Topic</span> Knowledge-enhanced reasoning, Multi-agent collaboration, etc.</span><br>
                â—‹ Research Collaboration in AI for Life Science.<br>
                <span style="padding-left: 0px;"><span class="label label-info">Topic</span> Reach out to me for an online / in-person chat (â˜•) on next-generation science accelerators, etc.</span><br>
            </font>
        </p>
        <hr>
        <p>
            <font size="3">
                <span class="label label-danger">News</span> [Nov. 2025] Our work â€œPersuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PDâ€ is published in EMNLP 2025.<br>
                <span class="label label-danger">News</span> [Nov. 2025] Our work â€œCCL-XCoT: An Efficient Cross-Lingual Knowledge Transfer Method for Mitigating Hallucination Generationâ€ is published in EMNLP 2025.<br>
                <span class="label label-danger">News</span> [Jun. 2025] Presented our work â€œCOGENT: A Curriculum-oriented Framework for Generating Grade-appropriate Educational Contentâ€ in BEA 2025.<br>
                <span class="label label-danger">News</span> [May. 2025] Presented our work â€œSingaKids: A Multilingual Multimodal Dialogic Tutor for Language Learningâ€ in ACL 2025 (Oral).<br>
                <span class="label label-danger">News</span> [May. 2025] Our work â€œReinforcing Compositional Retrieval: Retrieving Step-by-Step for Composing Informative Contextsâ€ is published in ACL 2025.<br>
                <span class="label label-danger">News</span> [Mar. 2025] Our work â€œScaling Up Collaborative Dialogue Analysis: An AI-driven Approach to Understanding Dialogue Patterns in Computational Thinking Educationâ€ got published in LAK 2025.<br>
                <span class="label label-danger">News</span> [Jan. 2025] Our paper â€œCrossIn: An Efficient Instruction Tuning Approach for Cross-Lingual Knowledge Alignmentâ€ won the ğŸ… Best Paper Award in SumEval@COLING 2025.<br>
                <span class="label label-danger">News</span> [Nov. 2024] Our paper â€œLearning planning-based reasoning by
                trajectories collection and process reward synthesizingâ€ won the ğŸ… Outstanding Paper Award in EMNLP 2024.<br>
                <span class="label label-danger">News</span> [Nov. 2024] Presented our work â€œPersonality-aware Student
                Simulation for Conversational Intelligent Tutoring Systemsâ€ in EMNLP 2024.<br>
                <span class="label label-danger">News</span> [Sep. 2024] Presented our work â€œOptimizing Code-Switching in
                Conversational Tutoring Systems: A Pedagogical Framework and Evaluationâ€ in SIGDIAL 2024.<br>
                <span class="label label-danger">News</span> [Sep. 2024] Our paper â€œCRAFT: Extracting and Tuning
                Cultural Instructions from the Wildâ€ won the ğŸ… Best Paper Award in C3NLP@ACL2024.<br>
                <span class="label label-danger">News</span> [Feb. 2024] Presented our work â€œScaffolding Language Learning
                via Multi-modal Tutoring Systems with Pedagogical Instructionsâ€ in IEEE CAI 2024.<br>
                <span class="label label-default">News</span> [Dec. 2023] Our paper â€œJoint Dialogue Topic Segmentation
                and Categorization: A Case Study on Clinical Spoken Conversationsâ€ won the ğŸ… Outstanding Paper Award in EMNLP 2023.<br>
                <span class="label label-default">News</span> [Jul. 2022] Presented our work â€œLearning from Bootstrapping and Stepwise Reinforcement Reward: A Semi-Supervised Framework for Text Style Transferâ€ in NAACL 2022.<br>
                <span class="label label-default">News</span> [Sep. 2021] Our paper â€œCoreference-Aware Dialogue Summarizationâ€ won the ğŸ… Best Paper Award in SIGDIAL 2021.<br>
            </font>
        </p>
        <hr>
        <p>
            <font size="3">
                <b>Academic Service</b><br>
                Assistant Program Chair in NeurIPS 2025. <br>
                Conference Program Committee, Reviewer, and Area Chair:<br>
                NeurIPS, ICLR, ACL, EMNLP, NAACL, AAAI, LAK, LERC, ICASSP, Interspeech, etc.<br>
                Conference Session Chair: ICASSP and Interspeech.<br>
                Journal Reviewer: IEEE TASLP, ACM CSUR, Neurocomputing, Computer Speech & Language, etc.<br>
            </font>
        </p>
    </div>
    <hr>
</div>

<footer style="display: flex; justify-content: center;">Â© 2025, Zhengyuan Liu</footer>

</body>

</html>
