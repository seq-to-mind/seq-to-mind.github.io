<!DOCTYPE html>
<html>

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    <link href="css/bootstrap.css" rel="stylesheet" media="screen">
    <link href="css/my-style.css" rel="stylesheet" media="screen">
    <script src="js/jquery.js"></script>
    <script src="js/bootstrap.js"></script>
    <title>Zhengyuan Liu | Institute for Infocomm Research, A*STAR</title>
</head>

<body>
<header></header>

<div class="container">
    <div>
        <h1>
            Zhengyuan Liu
        </h1>
        <div class="row">
            <div class="col-sm-7">
                <p>
                    Asst. Head of the AI4EDU Programme<br>
                    Tech Lead of Multimodal Generative AI Group<br>
                    Institute for Infocomm Research, A*STAR, Singapore<br>
                    IEEE Senior Member<br>
                </p>
                <p>
                    [<a href="mailto:i.liuzhengyuan@gmail.com">Email</a>]
                    [<a href="https://scholar.google.com.sg/citations?user=tqzidGsAAAAJ">Google Scholar</a>]
                    [<a href="https://www.linkedin.com/in/zhengyuanliu">LinkedIn</a>]
                </p>
                <p>
                    <span class="label label-danger">Research Interest</span><br>
                    Multimodal and Multilingual Foundation Models.<br>
                    Generative AI for Education, Healthcare, and Life Science.<br>
                    Accessibility, Reliability, and Explainability for Human-Centered AI.<br>
                </p>
            </div>
            <div class="col-sm-5" align="middle">
                <img src="assets/img/photo.jpeg" class="img-responsive" alt="Zhengyuan"
                     width="200">
            </div>
        </div>
        <hr>
        <p>
            <font size="3">
                <b>Current Key Projects</b><br>
                ğŸŒŸ AI for Education Programme | Human-centered AI<br>
                > Our vision is to transform how people learn knowledge and advance science by creating AI systems that
                can understand, reason, and collaborate across disciplines and languages.<br>
                ğŸš€ National Large Language Model Programme (MERaLiON SG)<br>
                > Working on improving multilingual and multimodal LLMs' capabilities of knowledge and reasoning.<br>
                <p>
                    <li><i>â€œImagination is more important than knowledge.â€ â€“ Albert Einstein.</i></li>
                <p>
            </font>
        </p>
        <hr>
        <p>
            <font size="3">
                <b>Join Us & Collaboration (ğŸ“§ just email me)</b><br>
                <b> > </b> Research Assistant / Student Intern in AI for Education. Remote intern is also welcome!<br>
                <span style="padding-left: 0px;"> <span class="label label-info">Topic</span> Conversational intelligent tutoring systems, Human-AI collaborative learning, etc.</span><br>
                <b> > </b> Research Assistant / Student Intern in Generative AI and Multimodal Fundation Models.<br>
                <span style="padding-left: 0px;"><span class="label label-info">Topic</span> Knowledge-enhanced reasoning, Multi-agent collaboration, etc.</span><br>
                <b> > </b> Research Collaboration in AI for Life Science & Healthcare.<br>
                <span style="padding-left: 0px;"><span class="label label-info">Topic</span> Reach out to me for an online / in-person chat (â˜•) on next-generation science accelerators, etc.</span><br>
            </font>
        </p>
        <hr>
        <p>
            <font size="3">
                <span class="label label-danger">News</span> [Mar. 2025] Our work â€œScaling Up Collaborative Dialogue Analysis: An AI-driven Approach to Understanding Dialogue Patterns in Computational Thinking Educationâ€ got published in LAK 2025.<br>
                <span class="label label-danger">News</span> [Jan. 2025] Our paper â€œCrossIn: An Efficient Instruction Tuning Approach for Cross-Lingual Knowledge Alignmentâ€ got the ğŸ… Best Paper Award in SumEval@COLING 2025.<br>
                <span class="label label-danger">News</span> [Nov. 2024] Our paper â€œLearning planning-based reasoning by
                trajectories collection and process reward synthesizingâ€ got the ğŸ… Outstanding Paper Award in EMNLP 2024.<br>
                <span class="label label-danger">News</span> [Nov. 2024] Presented our work â€œPersonality-aware Student
                Simulation for Conversational Intelligent Tutoring Systemsâ€ in EMNLP 2024.<br>
                <span class="label label-danger">News</span> [Sep. 2024] Presented our work â€œOptimizing Code-Switching in
                Conversational Tutoring Systems: A Pedagogical Framework and Evaluationâ€ in SIGDIAL 2024.<br>
                <span class="label label-danger">News</span> [Sep. 2024] Our paper â€œCRAFT: Extracting and Tuning
                Cultural Instructions from the Wildâ€ got the ğŸ… Best Paper Award in C3NLP@ACL2024.<br>
                <span class="label label-danger">News</span> [Feb. 2024] Presented our work â€œScaffolding Language Learning
                via Multi-modal Tutoring Systems with Pedagogical Instructionsâ€ in IEEE CAI 2024.<br>
                <span class="label label-default">News</span> [Dec. 2023] Our paper â€œJoint Dialogue Topic Segmentation
                and Categorization: A Case Study on Clinical Spoken Conversationsâ€ got the ğŸ… Outstanding Paper Award in EMNLP 2023.<br>
                <span class="label label-default">News</span> [Jul. 2022] Presented our work â€œLearning from Bootstrapping and Stepwise Reinforcement Reward: A Semi-Supervised Framework for Text Style Transferâ€ in NAACL 2022.<br>
                <span class="label label-default">News</span> [Sep. 2021] Our paper â€œCoreference-Aware Dialogue Summarizationâ€ got the ğŸ… Best Paper Award in SIGDIAL 2021.<br>
            </font>
        </p>
        <hr>
        <p>
            <font size="3">
                <b>Academic Service</b><br>
                Conference Program Committee and Reviewer: NeurIPS, ICLR, ACL, EMNLP, NAACL, AAAI, etc. <br>
                Conference Session Chair: ICASSP and Interspeech.<br>
                Journal Reviewer: IEEE TASLP, ACM CSUR, Neurocomputing, Computer Speech & Language, etc.<br>
            </font>
        </p>
    </div>
    <hr>
</div>

<footer style="display: flex; justify-content: center;">Â© 2025, Zhengyuan Liu</footer>

</body>

</html>
